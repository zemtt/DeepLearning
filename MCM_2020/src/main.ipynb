{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bit2044ea387b9340689ece04357539fae4",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCM 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MyData\n",
    "from torch import nn, Tensor\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-1\n",
    "num_epochs = 10\n",
    "\n",
    "class_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyData('1.tsv')\n",
    "train_data = data.train_data()\n",
    "test_data = data.test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sentence_matrix = [Tensor(item[0]).t() for item in batch]\n",
    "    labels = [item[1]-1 for item in batch]\n",
    "    labels = torch.Tensor(labels).long()\n",
    "    return [sentence_matrix,labels]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True,collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性模型实现\n",
    "class LinerClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinerClassifier, self).__init__()\n",
    "        self.L1 = nn.Sequential(\n",
    "            nn.Linear(100,20),\n",
    "            nn.ReLU(True))\n",
    "        self.L2 = nn.Sequential(\n",
    "            nn.Linear(20,5),\n",
    "            nn.LogSoftmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        sum_matrix = Tensor([])\n",
    "        for each in x:\n",
    "            # print(each.size())\n",
    "            sum_matrix = torch.cat((sum_matrix, each.sum(1).reshape(1, 100)), 0)\n",
    "        x = self.L1(sum_matrix)\n",
    "        x = self.L2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM模型实现\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.L1 = nn.LSTM(\n",
    "            input_size=class_num,\n",
    "            hidden_size=16,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bias=False\n",
    "        )\n",
    "        self.L2 = nn.Sequential(\n",
    "            nn.Linear(16 ,5),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = [each.t() for each in x]\n",
    "        x = pad_sequence(x, batch_first=True, padding_value=0)\n",
    "        output,(h_n,c_n) = self.L1(x)\n",
    "        # print(output.size())\n",
    "        output_in_last_timestep=h_n[-1,:,:]\n",
    "        x = self.L2(output_in_last_timestep)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "**********\nepoch 1\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-740ace2a8ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 向后传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Loss: {running_loss/len(train_loader):.6f}, Acc: {running_acc/len(train_loader):.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier()\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('*' * 10)\n",
    "    print(f'epoch {epoch+1}')\n",
    "    running_loss, running_acc = .0, .0\n",
    "    for sentence_matrixs, label in train_loader:\n",
    "        out = model(sentence_matrixs)\n",
    "        # print(out)\n",
    "        # print(out.size())\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        running_acc += (pred == label).float().mean()\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Train Loss: {running_loss/len(train_loader):.6f}, Acc: {running_acc/len(train_loader):.6f}')\n",
    "    model.eval()\n",
    "    eval_loss, eval_acc = .0, .0\n",
    "    for sentence_matrixs, label in test_loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(sentence_matrixs)\n",
    "            loss = criterion(out, label)\n",
    "        eval_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        eval_acc += (pred == label).float().mean()\n",
    "    acc.append(eval_acc/len(test_loader))\n",
    "    print(f'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}\\n')\n",
    "    \n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './ReNet-5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[-2.2246, -2.6913, -2.2769, -1.6287, -0.6438]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([4])\n/Users/tanchenxi/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  import sys\n"
    }
   ],
   "source": [
    "# from word2vec import load_model\n",
    "\n",
    "w2v_model = load_model()\n",
    "text = \"\"\"\n",
    "Great while it worked\tThis was a great hair dryer....for 8 months.  Yesterday the heating element stopped working and now it only blows cool air.  I thought since it was a Revlon product and it wasn't cheap that it would last for years.  I was wrong :(\n",
    "\"\"\"\n",
    "matrix = [Tensor([w2v_model[each] for each in text.split(' ') if each in w2v_model.wv.vocab]).t()]\n",
    "# print(matrix.size())\n",
    "out = model(matrix)\n",
    "print(out)\n",
    "_, pred = torch.max(out, 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([100, 13])\ntorch.Size([100, 19])\ntorch.Size([100, 11])\ntorch.Size([100, 86])\ntorch.Size([100, 57])\ntorch.Size([100, 23])\ntorch.Size([100, 55])\ntorch.Size([100, 180])\ntorch.Size([100, 22])\ntorch.Size([100, 24])\ntorch.Size([100, 24])\ntorch.Size([100, 34])\ntorch.Size([100, 157])\ntorch.Size([100, 4])\ntorch.Size([100, 38])\ntorch.Size([100, 62])\ntorch.Size([100, 162])\ntorch.Size([100, 106])\ntorch.Size([100, 107])\ntorch.Size([100, 67])\ntorch.Size([100, 7])\ntorch.Size([100, 15])\ntorch.Size([100, 29])\ntorch.Size([100, 36])\ntorch.Size([100, 38])\ntorch.Size([100, 36])\ntorch.Size([100, 9])\ntorch.Size([100, 59])\ntorch.Size([100, 16])\ntorch.Size([100, 58])\ntorch.Size([100, 34])\ntorch.Size([100, 11])\ntorch.Size([100, 190])\ntorch.Size([100, 45])\ntorch.Size([100, 39])\ntorch.Size([100, 11])\ntorch.Size([100, 25])\ntorch.Size([100, 8])\ntorch.Size([100, 58])\ntorch.Size([100, 66])\ntorch.Size([100, 49])\ntorch.Size([100, 212])\ntorch.Size([100, 13])\ntorch.Size([100, 145])\ntorch.Size([100, 17])\ntorch.Size([100, 19])\ntorch.Size([100, 58])\ntorch.Size([100, 25])\ntorch.Size([100, 34])\ntorch.Size([100, 18])\ntorch.Size([100, 54])\ntorch.Size([100, 25])\ntorch.Size([100, 76])\ntorch.Size([100, 51])\ntorch.Size([100, 430])\ntorch.Size([100, 158])\ntorch.Size([100, 3])\ntorch.Size([100, 14])\ntorch.Size([100, 47])\ntorch.Size([100, 340])\ntorch.Size([100, 234])\ntorch.Size([100, 83])\ntorch.Size([100, 49])\ntorch.Size([100, 4])\ntorch.Size([100, 49])\ntorch.Size([100, 3])\ntorch.Size([100, 142])\ntorch.Size([100, 3])\ntorch.Size([100, 22])\ntorch.Size([100, 8])\ntorch.Size([100, 6])\ntorch.Size([100, 24])\n"
    }
   ],
   "source": [
    "for sentence_matrixs, label in train_loader:\n",
    "    print(sentence_matrixs[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 1\n"
   ]
  }
 ]
}